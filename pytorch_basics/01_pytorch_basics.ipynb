{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMlF7SHA2Btcy3o26QM0wER"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Running Tensors and PyTorch objects on the GPUs (making faster computations)\n","\n","Use Google Colab with **changing runtime type** as **GPU**"],"metadata":{"id":"gJ4pl6svg1Yu"}},{"cell_type":"code","source":["! nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-g3NSYgxt5I7","executionInfo":{"status":"ok","timestamp":1664056976490,"user_tz":-180,"elapsed":5,"user":{"displayName":"Enise Zengin","userId":"10552883211498873314"}},"outputId":"2c38d219-73e3-4fcf-cfa7-b72bdc35446f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Sep 24 22:02:57 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["### Checking for GPU access with PyTorch"],"metadata":{"id":"zRL5fyrjhoD0"}},{"cell_type":"code","source":["import torch\n","torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OZ6qTOBOhn0l","executionInfo":{"status":"ok","timestamp":1664057562876,"user_tz":-180,"elapsed":255,"user":{"displayName":"Enise Zengin","userId":"10552883211498873314"}},"outputId":"5f5da3e9-c896-4cc5-adf8-f7f897af1ea5"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Setup device agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"1jSAlKQqiI2Z","executionInfo":{"status":"ok","timestamp":1664057563811,"user_tz":-180,"elapsed":9,"user":{"displayName":"Enise Zengin","userId":"10552883211498873314"}},"outputId":"e03707bb-aaa8-4bd9-af13-995d9879cf96"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Count number of devices\n","torch.cuda.device_count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eoI5OpGcicBf","executionInfo":{"status":"ok","timestamp":1664057293880,"user_tz":-180,"elapsed":4,"user":{"displayName":"Enise Zengin","userId":"10552883211498873314"}},"outputId":"05468901-7dbe-4c8d-e42c-a26b1059a8fb"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["### Putting tensors and models on the GPU"],"metadata":{"id":"m7MtnrIHi_3h"}},{"cell_type":"code","source":["# Create a tensor while default on the CPU\n","import torch\n","tensor = torch.tensor([1, 2, 3])\n","\n","# Tensor not on GPU\n","print(tensor, tensor.to(device))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7jU0BByziziw","executionInfo":{"status":"ok","timestamp":1664057512879,"user_tz":-180,"elapsed":292,"user":{"displayName":"Enise Zengin","userId":"10552883211498873314"}},"outputId":"6f9e8ed0-0f2e-4639-aa21-6b2cc7ea354f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3]) tensor([1, 2, 3])\n"]}]},{"cell_type":"code","source":["import torch\n","tensor_on_gpu = tensor.to(device)\n","tensor_on_gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97_vbFxXjXC9","executionInfo":{"status":"ok","timestamp":1664057830649,"user_tz":-180,"elapsed":251,"user":{"displayName":"Enise Zengin","userId":"10552883211498873314"}},"outputId":"76f082c4-fe8c-497d-9f37-f085e2d397e3"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3], device='cuda:0')"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["### Moving tensors back to the GPU"],"metadata":{"id":"kwnO9ubKj6-E"}},{"cell_type":"code","source":["# If tensor is on GPU, can't transform it to NumPy\n","tensor_on_gpu.numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":190},"id":"BjAA3r31j4Z3","executionInfo":{"status":"error","timestamp":1664057833259,"user_tz":-180,"elapsed":270,"user":{"displayName":"Enise Zengin","userId":"10552883211498873314"}},"outputId":"850ff978-7651-4a77-cca4-bf30804564ae"},"execution_count":12,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-b7da913938a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If tensor is on GPU, can't transform it to NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."]}]},{"cell_type":"code","source":["# To fix it, first set it to the CPU\n","tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n","tensor_back_on_cpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-w9pLGlGkQ5H","executionInfo":{"status":"ok","timestamp":1664057835918,"user_tz":-180,"elapsed":244,"user":{"displayName":"Enise Zengin","userId":"10552883211498873314"}},"outputId":"fd54c740-8728-4c34-d876-7c8c35fc2cae"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 2, 3])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["tensor_on_gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kzj8cx6Hkslv","executionInfo":{"status":"ok","timestamp":1664057858673,"user_tz":-180,"elapsed":271,"user":{"displayName":"Enise Zengin","userId":"10552883211498873314"}},"outputId":"cf673446-92ca-4605-a945-620ac49464b3"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3], device='cuda:0')"]},"metadata":{},"execution_count":14}]}]}